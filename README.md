# Neural Navigator ğŸ§ ğŸ§­

Neural Navigator is a multimodal AI system that combines computer vision and natural language understanding to predict navigation paths. Given a 2D map image and a text instruction (e.g., â€œGo to the Green Squareâ€), the model generates a sequence of (x, y) coordinates representing the navigation trajectory.

This project was developed as part of a Robotics AI Engineer internship technical assignment.

---

## ğŸš€ Key Features

- Multimodal learning using vision and language
- CNN-based image encoder
- LSTM-based text encoder
- Sequence decoder for trajectory prediction
- End-to-end training pipeline
- Visual inference with predicted vs ground-truth paths

---

## ğŸ§  Model Architecture

The system processes two inputs:
- A map image
- A natural language navigation command

The image is encoded using a CNN to extract spatial features, while the text instruction is encoded using an embedding layer followed by an LSTM. These representations are fused and passed to an LSTM-based decoder that predicts a fixed-length sequence of (x, y) coordinates representing the navigation path.

---

## ğŸ“ Project Structure

neural-navigator/
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ dataset.py # Dataset loading and preprocessing
â”‚ â”œâ”€â”€ model.py # Multimodal neural network
â”‚ â”œâ”€â”€ train.py # Training pipeline
â”‚ â””â”€â”€ infer.py # Inference and visualization
â”œâ”€â”€ sample_output/
â”‚ â””â”€â”€ result.png # Sample inference result
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


Datasets, model checkpoints, and generated outputs are excluded using `.gitignore` to keep the repository clean and reproducible.

---

## âš™ï¸ How to Run

### Training
```bash
python src/train.py
python src/infer.py

âš ï¸ Challenges & Solutions
One major challenge was handling inconsistent annotation formats in the dataset, where image filenames and text commands were stored using different keys. This was solved by implementing a robust dataset loader that dynamically adapts to varying annotation schemas.
Another challenge involved Python module resolution issues in notebook and script-based execution environments. This was addressed by restructuring the project using a clean src/ layout and consistent import patterns.
Predicting full navigation trajectories instead of single target points was also non-trivial. An LSTM-based sequence decoder with fixed-length padding and mean squared error loss was used to ensure stable and consistent training.

ğŸ“ˆ Results
The model successfully learns to predict navigation paths from combined visual and textual inputs. Training loss decreases consistently, and inference visualizations show reasonable alignment between predicted and ground-truth trajectories.

ğŸ› ï¸ Tech Stack
Python
PyTorch
Torchvision
NumPy
Matplotlib

âœ… Conclusion
This project demonstrates a clean, modular, and reproducible approach to multimodal AI for navigation tasks. Emphasis was placed on robustness, clarity, and real-world engineering practices rather than overfitting for benchmark scores.

---

## ğŸ”¥ FINAL STATUS (CONFIRMATION)

After this:
- âœ… README complete
- âœ… Image visible on GitHub
- âœ… Assignment-ready
- âœ… Interview-safe explanations

ğŸ’ª **Nee romba clean-aa finish pannita da**.

### Ippo last step venuma?
If yes, Iâ€™ll give **perfect submission mail / WhatsApp message**.

Reply ğŸ‘‡  
